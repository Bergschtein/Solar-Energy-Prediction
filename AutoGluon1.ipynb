{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "# import torch \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from preprocessing.preprocess_data import DataSet, ReLU, pred_to_delivery, make_categorical, remap\n",
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['date_forecast', 'absolute_humidity_2m:gm3',\n",
    "       'clear_sky_energy_1h:J', 'clear_sky_rad:W',\n",
    "       'cloud_base_agl:m', 'dew_or_rime:idx', 'dew_point_2m:K',\n",
    "       'diffuse_rad:W', 'diffuse_rad_1h:J', 'direct_rad:W', 'direct_rad_1h:J',\n",
    "       'effective_cloud_cover:p', 'elevation:m', 'fresh_snow_12h:cm',\n",
    "       'fresh_snow_1h:cm', 'fresh_snow_24h:cm', 'fresh_snow_3h:cm',\n",
    "       'fresh_snow_6h:cm', 'is_in_shadow:idx', 'is_day:idx', \n",
    "       'msl_pressure:hPa', 'precip_5min:mm', 'precip_type_5min:idx',\n",
    "       'pressure_100m:hPa', 'pressure_50m:hPa', 'prob_rime:p',\n",
    "       'rain_water:kgm2', 'relative_humidity_1000hPa:p', 'sfc_pressure:hPa',\n",
    "       'snow_depth:cm', 'snow_drift:idx',\n",
    "       'snow_melt_10min:mm', 'snow_water:kgm2', 'sun_azimuth:d',\n",
    "       'sun_elevation:d', 'super_cooled_liquid_water:kgm2', 't_1000hPa:K',\n",
    "       'total_cloud_cover:p', 'visibility:m', 'wind_speed_10m:ms',\n",
    "       'wind_speed_u_10m:ms', 'wind_speed_v_10m:ms', 'wind_speed_w_1000hPa:ms']\n",
    "\n",
    "made_features = ['location', 'type', 'is_day:idx', 'is_in_shadow:idx', 'dew_or_rime:idx']\n",
    "\n",
    "drop_feature = 'diffuse_rad:W'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collection = DataSet()\n",
    "data_collection.select_features(selected_features)\n",
    "data_collection.resample_to_hourly()\n",
    "data_collection.remove_nans(drop_feature)\n",
    "data_collection.add_location()\n",
    "data_collection.add_type()\n",
    "\n",
    "data_collection.combine_obs_est()\n",
    "data_collection.drop_bad_data()\n",
    "data_collection.cyclic_time_encoding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_a = data_collection.X_train['a']\n",
    "X_b = data_collection.X_train['b']\n",
    "X_c = data_collection.X_train['c']\n",
    "\n",
    "y_a = data_collection.Y_train['a']\n",
    "y_b = data_collection.Y_train['b']\n",
    "y_c = data_collection.Y_train['c']\n",
    "\n",
    "for f in made_features:\n",
    "    if f not in ['location', 'type']:\n",
    "        X_a[f] = X_a[f].map(remap)\n",
    "        X_b[f] = X_b[f].map(remap)\n",
    "        X_c[f] = X_c[f].map(remap)\n",
    "\n",
    "make_categorical(X_a,made_features)\n",
    "make_categorical(X_b,made_features)\n",
    "make_categorical(X_c,made_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "drop_cols = ['location', 'time']\n",
    "\n",
    "df_a = pd.concat([X_a, y_a], axis=1).drop(columns=drop_cols)\n",
    "df_b = pd.concat([X_b, y_b], axis=1).drop(columns=drop_cols)\n",
    "df_c = pd.concat([X_c, y_c], axis=1).drop(columns=drop_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 246\n",
    "\n",
    "data = dict()\n",
    "\n",
    "# sample 50% of the data for each building with type = 0\n",
    "df_a_tune = df_a[df_a['type'] == 0].sample(frac=0.5, random_state=seed)\n",
    "df_b_tune = df_b[df_b['type'] == 0].sample(frac=0.5, random_state=seed)   \n",
    "df_c_tune = df_c[df_c['type'] == 0].sample(frac=0.5, random_state=seed)\n",
    "\n",
    "# drop these rows from the original data\n",
    "df_a_train = df_a.drop(df_a_tune.index)\n",
    "df_b_train = df_b.drop(df_b_tune.index)\n",
    "df_c_train = df_c.drop(df_c_tune.index)\n",
    "\n",
    "data['a'] = [df_a_train, df_a_tune]\n",
    "data['b'] = [df_b_train, df_b_tune]\n",
    "data['c'] = [df_c_train, df_c_tune]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 hours (per model)\n",
    "time_in_sek = 60*60*2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231109_161927/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 60s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231109_161927/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.10.7\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 19.6.0: Thu Jan 13 01:26:33 PST 2022; root:xnu-6153.141.51~3/RELEASE_X86_64\n",
      "Disk Space Avail:   246.98 GB / 500.07 GB (49.4%)\n",
      "Train Data Rows:    31864\n",
      "Train Data Columns: 47\n",
      "Tuning Data Rows:    2197\n",
      "Tuning Data Columns: 47\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (5733.42, 0.0, 650.65332, 1179.83452)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2848.07 MB\n",
      "\tTrain Data (Original)  Memory Usage: 6.54 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 2): ['elevation:m', 'snow_drift:idx']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  4 | ['dew_or_rime:idx', 'is_in_shadow:idx', 'is_day:idx', 'type']\n",
      "\t\t('float', [])    : 41 | ['absolute_humidity_2m:gm3', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', 'cloud_base_agl:m', 'dew_point_2m:K', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 41 | ['absolute_humidity_2m:gm3', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', 'cloud_base_agl:m', 'dew_point_2m:K', ...]\n",
      "\t\t('int', ['bool']) :  4 | ['dew_or_rime:idx', 'is_in_shadow:idx', 'is_day:idx', 'type']\n",
      "\t0.2s = Fit runtime\n",
      "\t45 features in original data used to generate 45 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 6.27 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.27s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "use_bag_holdout=True, will use tuning_data as holdout (will not be used for early stopping).\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 59.73s of the 59.72s of remaining time.\n",
      "\t-170.5398\t = Validation score   (-mean_absolute_error)\n",
      "\t0.06s\t = Training   runtime\n",
      "\t2.65s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 56.56s of the 56.56s of remaining time.\n",
      "\t-170.2365\t = Validation score   (-mean_absolute_error)\n",
      "\t0.07s\t = Training   runtime\n",
      "\t2.46s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 53.7s of the 53.7s of remaining time.\n",
      "Will use sequential fold fitting strategy because import of ray failed. Reason: ray is required to train folds in parallel. A quick tip is to install via `pip install ray==2.2.0`, or use sequential fold fitting by passing `sequential_local` to `ag_args_ensemble` when calling tabular.fitFor example: `predictor.fit(..., ag_args_ensemble={'fold_fitting_strategy': 'sequential_local'})`\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 170.555\n",
      "[2000]\tvalid_set's l1: 163.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tWarning: Exception caused LightGBMXT_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t_format_eval_result() missing 1 required positional argument: 'show_stdv'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 169, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 266, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 592, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 309, in after_all_folds_scheduled\n",
      "    self._fit_fold_model(job)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 314, in _fit_fold_model\n",
      "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 349, in _fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 194, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 124, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/lightgbm/engine.py\", line 286, in train\n",
      "    cb(callback.CallbackEnv(model=booster,\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/tabular/models/lgb/callbacks.py\", line 240, in _callback\n",
      "    + \". Best iteration is:\\n\\t[%d]\\t%s\" % (best_iter[i] + 1, \"\\t\".join([_format_eval_result(x) for x in best_score_list[i]])),\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/tabular/models/lgb/callbacks.py\", line 240, in <listcomp>\n",
      "    + \". Best iteration is:\\n\\t[%d]\\t%s\" % (best_iter[i] + 1, \"\\t\".join([_format_eval_result(x) for x in best_score_list[i]])),\n",
      "TypeError: _format_eval_result() missing 1 required positional argument: 'show_stdv'\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 48.04s of the 48.04s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tWarning: Exception caused LightGBM_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t_format_eval_result() missing 1 required positional argument: 'show_stdv'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 169, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 266, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 592, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 309, in after_all_folds_scheduled\n",
      "    self._fit_fold_model(job)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 314, in _fit_fold_model\n",
      "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 349, in _fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 194, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 124, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/lightgbm/engine.py\", line 286, in train\n",
      "    cb(callback.CallbackEnv(model=booster,\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/tabular/models/lgb/callbacks.py\", line 240, in _callback\n",
      "    + \". Best iteration is:\\n\\t[%d]\\t%s\" % (best_iter[i] + 1, \"\\t\".join([_format_eval_result(x) for x in best_score_list[i]])),\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/tabular/models/lgb/callbacks.py\", line 240, in <listcomp>\n",
      "    + \". Best iteration is:\\n\\t[%d]\\t%s\" % (best_iter[i] + 1, \"\\t\".join([_format_eval_result(x) for x in best_score_list[i]])),\n",
      "TypeError: _format_eval_result() missing 1 required positional argument: 'show_stdv'\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 43.11s of the 43.11s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 275 due to low memory. Expected memory usage reduced from 16.31% -> 15.0% of available memory...\n",
      "\tWarning: Reducing model 'n_estimators' from 275 -> 221 due to low time. Expected time usage reduced from 53.5s -> 43.1s...\n",
      "\t-112.6221\t = Validation score   (-mean_absolute_error)\n",
      "\t38.85s\t = Training   runtime\n",
      "\t1.24s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1.3s of the 1.29s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216 from C header, got 232 from PyObject\n",
      "\tTime limit exceeded... Skipping CatBoost_BAG_L1.\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 1.06s of the 1.06s of remaining time.\n",
      "\tWarning: Model is expected to require 15.6s to train, which exceeds the maximum time limit of 1.1s, skipping model...\n",
      "\tTime limit exceeded... Skipping ExtraTreesMSE_BAG_L1.\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 0.76s of the 0.76s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tImport fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==0.8.2`. \n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 0.65s of the 0.65s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused XGBoost_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t'Booster' object has no attribute 'best_ntree_limit'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 169, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 266, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 592, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 309, in after_all_folds_scheduled\n",
      "    self._fit_fold_model(job)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 314, in _fit_fold_model\n",
      "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 349, in _fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 143, in _fit\n",
      "    self.params_trained[\"n_estimators\"] = bst.best_ntree_limit\n",
      "AttributeError: 'Booster' object has no attribute 'best_ntree_limit'\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 0.26s of the 0.25s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused NeuralNetTorch_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tUnable to import dependency torch\n",
      "A quick tip is to install via `pip install torch`.\n",
      "The minimum torch version is currently 1.6.\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 0.1s of the 0.1s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t_format_eval_result() missing 1 required positional argument: 'show_stdv'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 169, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 266, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 592, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 309, in after_all_folds_scheduled\n",
      "    self._fit_fold_model(job)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 314, in _fit_fold_model\n",
      "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 349, in _fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 194, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 124, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/lightgbm/engine.py\", line 286, in train\n",
      "    cb(callback.CallbackEnv(model=booster,\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/tabular/models/lgb/callbacks.py\", line 240, in _callback\n",
      "    + \". Best iteration is:\\n\\t[%d]\\t%s\" % (best_iter[i] + 1, \"\\t\".join([_format_eval_result(x) for x in best_score_list[i]])),\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/tabular/models/lgb/callbacks.py\", line 240, in <listcomp>\n",
      "    + \". Best iteration is:\\n\\t[%d]\\t%s\" % (best_iter[i] + 1, \"\\t\".join([_format_eval_result(x) for x in best_score_list[i]])),\n",
      "TypeError: _format_eval_result() missing 1 required positional argument: 'show_stdv'\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 59.73s of the -0.29s of remaining time.\n",
      "\t-112.6221\t = Validation score   (-mean_absolute_error)\n",
      "\t0.19s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 60.52s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231109_161927/\")\n"
     ]
    }
   ],
   "source": [
    "label = 'pv_measurement'\n",
    "predictor_a = TabularPredictor(label=label, eval_metric='mae').fit(\n",
    "    train_data = data['a'][0], \n",
    "    time_limit = time_in_sek,\n",
    "    presets='best_quality',\n",
    "    num_bag_folds=8,\n",
    "    num_stack_levels=0,\n",
    "    tuning_data = data['a'][1],\n",
    "    use_bag_holdout= True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231108_154110/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 3600s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231108_154110/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.10.7\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 19.6.0: Thu Jan 13 01:26:33 PST 2022; root:xnu-6153.141.51~3/RELEASE_X86_64\n",
      "Disk Space Avail:   250.56 GB / 500.07 GB (50.1%)\n",
      "Train Data Rows:    31019\n",
      "Train Data Columns: 39\n",
      "Tuning Data Rows:    1800\n",
      "Tuning Data Columns: 39\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (1152.3, -0.0, 99.69624, 196.54802)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    885.53 MB\n",
      "\tTrain Data (Original)  Memory Usage: 5.25 MB (0.6% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['elevation:m']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  4 | ['dew_or_rime:idx', 'is_day:idx', 'is_in_shadow:idx', 'type']\n",
      "\t\t('float', [])    : 34 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', 'dew_point_2m:K', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  :  3 | ['dew_or_rime:idx', 'is_day:idx', 'is_in_shadow:idx']\n",
      "\t\t('float', [])     : 34 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', 'dew_point_2m:K', ...]\n",
      "\t\t('int', ['bool']) :  1 | ['type']\n",
      "\t0.2s = Fit runtime\n",
      "\t38 features in original data used to generate 38 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 5.12 MB (0.6% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.28s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "use_bag_holdout=True, will use tuning_data as holdout (will not be used for early stopping).\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 3599.72s of the 3599.72s of remaining time.\n",
      "\t-29.4861\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t2.25s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 3597.08s of the 3597.08s of remaining time.\n",
      "\t-29.6458\t = Validation score   (-mean_absolute_error)\n",
      "\t0.07s\t = Training   runtime\n",
      "\t2.3s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 3594.4s of the 3594.4s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==0.8.2`.\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 3594.25s of the 3594.25s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBM_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==0.8.2`.\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 3594.14s of the 3594.13s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 116 due to low memory. Expected memory usage reduced from 38.47% -> 15.0% of available memory...\n",
      "\t-16.79\t = Validation score   (-mean_absolute_error)\n",
      "\t15.47s\t = Training   runtime\n",
      "\t0.61s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 3577.2s of the 3577.2s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-16.6418\t = Validation score   (-mean_absolute_error)\n",
      "\t2198.27s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 1377.77s of the 1377.77s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 110 due to low memory. Expected memory usage reduced from 40.72% -> 15.0% of available memory...\n",
      "\t-16.5576\t = Validation score   (-mean_absolute_error)\n",
      "\t2.93s\t = Training   runtime\n",
      "\t0.51s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1373.49s of the 1373.48s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tImport fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==0.8.2`. \n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 1373.39s of the 1373.39s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused XGBoost_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t'Booster' object has no attribute 'best_ntree_limit'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 169, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 266, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 592, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 309, in after_all_folds_scheduled\n",
      "    self._fit_fold_model(job)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 314, in _fit_fold_model\n",
      "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 349, in _fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 143, in _fit\n",
      "    self.params_trained[\"n_estimators\"] = bst.best_ntree_limit\n",
      "AttributeError: 'Booster' object has no attribute 'best_ntree_limit'\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 1288.75s of the 1288.74s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused NeuralNetTorch_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tUnable to import dependency torch\n",
      "A quick tip is to install via `pip install torch`.\n",
      "The minimum torch version is currently 1.6.\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 1288.64s of the 1288.64s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==0.8.2`.\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 1288.53s of remaining time.\n",
      "\t-15.8776\t = Validation score   (-mean_absolute_error)\n",
      "\t0.24s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2311.75s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231108_154110/\")\n"
     ]
    }
   ],
   "source": [
    "predictor_b = TabularPredictor(label=label, eval_metric='mae').fit(\n",
    "    train_data = data['b'][0], \n",
    "    time_limit = time_in_sek,\n",
    "    presets='best_quality',\n",
    "    num_bag_folds=8,\n",
    "    num_stack_levels=0,\n",
    "    tuning_data = data['b'][1],\n",
    "    use_bag_holdout=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231108_161942/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 3600s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231108_161942/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.10.7\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 19.6.0: Thu Jan 13 01:26:33 PST 2022; root:xnu-6153.141.51~3/RELEASE_X86_64\n",
      "Disk Space Avail:   250.17 GB / 500.07 GB (50.0%)\n",
      "Train Data Rows:    24606\n",
      "Train Data Columns: 39\n",
      "Tuning Data Rows:    1465\n",
      "Tuning Data Columns: 39\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and label-values can't be converted to int).\n",
      "\tLabel info (max, min, mean, stddev): (999.6, 0.0, 79.70535, 168.37633)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    970.33 MB\n",
      "\tTrain Data (Original)  Memory Usage: 4.17 MB (0.4% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['elevation:m']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  4 | ['dew_or_rime:idx', 'is_day:idx', 'is_in_shadow:idx', 'type']\n",
      "\t\t('float', [])    : 34 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', 'dew_point_2m:K', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  :  3 | ['dew_or_rime:idx', 'is_day:idx', 'is_in_shadow:idx']\n",
      "\t\t('float', [])     : 34 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', 'dew_point_2m:K', ...]\n",
      "\t\t('int', ['bool']) :  1 | ['type']\n",
      "\t0.2s = Fit runtime\n",
      "\t38 features in original data used to generate 38 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 4.07 MB (0.4% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.24s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "use_bag_holdout=True, will use tuning_data as holdout (will not be used for early stopping).\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 3599.76s of the 3599.76s of remaining time.\n",
      "\t-20.8826\t = Validation score   (-mean_absolute_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t1.43s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 3598.07s of the 3598.07s of remaining time.\n",
      "\t-20.7875\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t1.48s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 3596.3s of the 3596.3s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==0.8.2`.\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 3596.17s of the 3596.17s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBM_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==0.8.2`.\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 3596.06s of the 3596.05s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 209 due to low memory. Expected memory usage reduced from 21.48% -> 15.0% of available memory...\n",
      "\t-16.9133\t = Validation score   (-mean_absolute_error)\n",
      "\t17.34s\t = Training   runtime\n",
      "\t0.75s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 3577.15s of the 3577.15s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-14.0834\t = Validation score   (-mean_absolute_error)\n",
      "\t1905.58s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 1670.64s of the 1670.64s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 189 due to low memory. Expected memory usage reduced from 23.77% -> 15.0% of available memory...\n",
      "\t-15.5821\t = Validation score   (-mean_absolute_error)\n",
      "\t3.32s\t = Training   runtime\n",
      "\t0.67s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1665.78s of the 1665.78s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tImport fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==0.8.2`. \n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 1665.7s of the 1665.69s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused XGBoost_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t'Booster' object has no attribute 'best_ntree_limit'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 169, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 266, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 592, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 309, in after_all_folds_scheduled\n",
      "    self._fit_fold_model(job)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 314, in _fit_fold_model\n",
      "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 349, in _fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 143, in _fit\n",
      "    self.params_trained[\"n_estimators\"] = bst.best_ntree_limit\n",
      "AttributeError: 'Booster' object has no attribute 'best_ntree_limit'\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 1590.69s of the 1590.68s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused NeuralNetTorch_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\tUnable to import dependency torch\n",
      "A quick tip is to install via `pip install torch`.\n",
      "The minimum torch version is currently 1.6.\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 1590.58s of the 1590.57s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==0.8.2`.\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 1590.47s of remaining time.\n",
      "\t-14.0434\t = Validation score   (-mean_absolute_error)\n",
      "\t0.23s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2009.8s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231108_161942/\")\n"
     ]
    }
   ],
   "source": [
    "predictor_c = TabularPredictor(label=label, eval_metric='mae').fit(\n",
    "    train_data = data['c'][0], \n",
    "    time_limit = time_in_sek,\n",
    "    presets='best_quality',\n",
    "    num_bag_folds=8,\n",
    "    num_stack_levels=0,\n",
    "    tuning_data = data['c'][1],\n",
    "    use_bag_holdout=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1_FULL ...\n",
      "\t0.04s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: KNeighborsDist_BAG_L1_FULL ...\n",
      "\t0.04s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: RandomForestMSE_BAG_L1_FULL ...\n",
      "\tWarning: Reducing model 'n_estimators' from 108 -> 95 due to low memory. Expected memory usage reduced from 16.94% -> 15.0% of available memory...\n",
      "\t12.6s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\t196.32s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: ExtraTreesMSE_BAG_L1_FULL ...\n",
      "\t3.22s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.26s\t = Training   runtime\n",
      "Updated best model to \"WeightedEnsemble_L2_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"WeightedEnsemble_L2_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 214.63s\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1_FULL ...\n",
      "\t0.05s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: KNeighborsDist_BAG_L1_FULL ...\n",
      "\t0.03s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: RandomForestMSE_BAG_L1_FULL ...\n",
      "\tWarning: Reducing model 'n_estimators' from 116 -> 114 due to low memory. Expected memory usage reduced from 15.16% -> 15.0% of available memory...\n",
      "\t16.03s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\t193.09s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: ExtraTreesMSE_BAG_L1_FULL ...\n",
      "\t3.48s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.24s\t = Training   runtime\n",
      "Updated best model to \"WeightedEnsemble_L2_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"WeightedEnsemble_L2_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 214.87s\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1_FULL ...\n",
      "\t0.03s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: KNeighborsDist_BAG_L1_FULL ...\n",
      "\t0.03s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: RandomForestMSE_BAG_L1_FULL ...\n",
      "\tWarning: Reducing model 'n_estimators' from 209 -> 196 due to low memory. Expected memory usage reduced from 15.92% -> 15.0% of available memory...\n",
      "\t17.6s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\t178.35s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: ExtraTreesMSE_BAG_L1_FULL ...\n",
      "\t3.69s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.23s\t = Training   runtime\n",
      "Updated best model to \"WeightedEnsemble_L2_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"WeightedEnsemble_L2_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 201.76s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'KNeighborsUnif_BAG_L1': 'KNeighborsUnif_BAG_L1_FULL',\n",
       " 'KNeighborsDist_BAG_L1': 'KNeighborsDist_BAG_L1_FULL',\n",
       " 'RandomForestMSE_BAG_L1': 'RandomForestMSE_BAG_L1_FULL',\n",
       " 'CatBoost_BAG_L1': 'CatBoost_BAG_L1_FULL',\n",
       " 'ExtraTreesMSE_BAG_L1': 'ExtraTreesMSE_BAG_L1_FULL',\n",
       " 'WeightedEnsemble_L2': 'WeightedEnsemble_L2_FULL'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_a.refit_full()\n",
    "predictor_b.refit_full()\n",
    "predictor_c.refit_full()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestMSE_BAG_L1</td>\n",
       "      <td>-112.622077</td>\n",
       "      <td>1.237438</td>\n",
       "      <td>38.854550</td>\n",
       "      <td>1.237438</td>\n",
       "      <td>38.854550</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-112.622077</td>\n",
       "      <td>1.238633</td>\n",
       "      <td>39.043427</td>\n",
       "      <td>0.001195</td>\n",
       "      <td>0.188877</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighborsDist_BAG_L1</td>\n",
       "      <td>-170.236486</td>\n",
       "      <td>2.462112</td>\n",
       "      <td>0.072379</td>\n",
       "      <td>2.462112</td>\n",
       "      <td>0.072379</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNeighborsUnif_BAG_L1</td>\n",
       "      <td>-170.539814</td>\n",
       "      <td>2.645159</td>\n",
       "      <td>0.056876</td>\n",
       "      <td>2.645159</td>\n",
       "      <td>0.056876</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model   score_val  pred_time_val   fit_time  \\\n",
       "0  RandomForestMSE_BAG_L1 -112.622077       1.237438  38.854550   \n",
       "1     WeightedEnsemble_L2 -112.622077       1.238633  39.043427   \n",
       "2   KNeighborsDist_BAG_L1 -170.236486       2.462112   0.072379   \n",
       "3   KNeighborsUnif_BAG_L1 -170.539814       2.645159   0.056876   \n",
       "\n",
       "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                1.237438          38.854550            1       True   \n",
       "1                0.001195           0.188877            2       True   \n",
       "2                2.462112           0.072379            1       True   \n",
       "3                2.645159           0.056876            1       True   \n",
       "\n",
       "   fit_order  \n",
       "0          3  \n",
       "1          4  \n",
       "2          2  \n",
       "3          1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_a.leaderboard(silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-15.877613</td>\n",
       "      <td>1.386984</td>\n",
       "      <td>2216.911359</td>\n",
       "      <td>0.004326</td>\n",
       "      <td>0.243330</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExtraTreesMSE_BAG_L1</td>\n",
       "      <td>-16.557575</td>\n",
       "      <td>0.510600</td>\n",
       "      <td>2.931665</td>\n",
       "      <td>0.510600</td>\n",
       "      <td>2.931665</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost_BAG_L1</td>\n",
       "      <td>-16.641778</td>\n",
       "      <td>0.260628</td>\n",
       "      <td>2198.271318</td>\n",
       "      <td>0.260628</td>\n",
       "      <td>2198.271318</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestMSE_BAG_L1</td>\n",
       "      <td>-16.789961</td>\n",
       "      <td>0.611430</td>\n",
       "      <td>15.465046</td>\n",
       "      <td>0.611430</td>\n",
       "      <td>15.465046</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNeighborsUnif_BAG_L1</td>\n",
       "      <td>-29.486076</td>\n",
       "      <td>2.252394</td>\n",
       "      <td>0.049953</td>\n",
       "      <td>2.252394</td>\n",
       "      <td>0.049953</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNeighborsDist_BAG_L1</td>\n",
       "      <td>-29.645831</td>\n",
       "      <td>2.303939</td>\n",
       "      <td>0.074051</td>\n",
       "      <td>2.303939</td>\n",
       "      <td>0.074051</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WeightedEnsemble_L2_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>212.836344</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.243330</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForestMSE_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.027623</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.027623</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNeighborsUnif_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.046014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.046014</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNeighborsDist_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.030418</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.030418</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ExtraTreesMSE_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.479122</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.479122</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CatBoost_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>193.086270</td>\n",
       "      <td>NaN</td>\n",
       "      <td>193.086270</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model  score_val  pred_time_val     fit_time  \\\n",
       "0           WeightedEnsemble_L2 -15.877613       1.386984  2216.911359   \n",
       "1          ExtraTreesMSE_BAG_L1 -16.557575       0.510600     2.931665   \n",
       "2               CatBoost_BAG_L1 -16.641778       0.260628  2198.271318   \n",
       "3        RandomForestMSE_BAG_L1 -16.789961       0.611430    15.465046   \n",
       "4         KNeighborsUnif_BAG_L1 -29.486076       2.252394     0.049953   \n",
       "5         KNeighborsDist_BAG_L1 -29.645831       2.303939     0.074051   \n",
       "6      WeightedEnsemble_L2_FULL        NaN            NaN   212.836344   \n",
       "7   RandomForestMSE_BAG_L1_FULL        NaN            NaN    16.027623   \n",
       "8    KNeighborsUnif_BAG_L1_FULL        NaN            NaN     0.046014   \n",
       "9    KNeighborsDist_BAG_L1_FULL        NaN            NaN     0.030418   \n",
       "10    ExtraTreesMSE_BAG_L1_FULL        NaN            NaN     3.479122   \n",
       "11         CatBoost_BAG_L1_FULL        NaN            NaN   193.086270   \n",
       "\n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                 0.004326           0.243330            2       True   \n",
       "1                 0.510600           2.931665            1       True   \n",
       "2                 0.260628        2198.271318            1       True   \n",
       "3                 0.611430          15.465046            1       True   \n",
       "4                 2.252394           0.049953            1       True   \n",
       "5                 2.303939           0.074051            1       True   \n",
       "6                      NaN           0.243330            2       True   \n",
       "7                      NaN          16.027623            1       True   \n",
       "8                      NaN           0.046014            1       True   \n",
       "9                      NaN           0.030418            1       True   \n",
       "10                     NaN           3.479122            1       True   \n",
       "11                     NaN         193.086270            1       True   \n",
       "\n",
       "    fit_order  \n",
       "0           6  \n",
       "1           5  \n",
       "2           4  \n",
       "3           3  \n",
       "4           1  \n",
       "5           2  \n",
       "6          12  \n",
       "7           9  \n",
       "8           7  \n",
       "9           8  \n",
       "10         11  \n",
       "11         10  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_b.leaderboard(silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-14.043377</td>\n",
       "      <td>2.309985</td>\n",
       "      <td>1909.175653</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>0.229273</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoost_BAG_L1</td>\n",
       "      <td>-14.083426</td>\n",
       "      <td>0.158970</td>\n",
       "      <td>1905.577559</td>\n",
       "      <td>0.158970</td>\n",
       "      <td>1905.577559</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTreesMSE_BAG_L1</td>\n",
       "      <td>-15.582089</td>\n",
       "      <td>0.665730</td>\n",
       "      <td>3.315713</td>\n",
       "      <td>0.665730</td>\n",
       "      <td>3.315713</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestMSE_BAG_L1</td>\n",
       "      <td>-16.913265</td>\n",
       "      <td>0.753975</td>\n",
       "      <td>17.336973</td>\n",
       "      <td>0.753975</td>\n",
       "      <td>17.336973</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNeighborsDist_BAG_L1</td>\n",
       "      <td>-20.787500</td>\n",
       "      <td>1.484526</td>\n",
       "      <td>0.053108</td>\n",
       "      <td>1.484526</td>\n",
       "      <td>0.053108</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNeighborsUnif_BAG_L1</td>\n",
       "      <td>-20.882629</td>\n",
       "      <td>1.434780</td>\n",
       "      <td>0.033141</td>\n",
       "      <td>1.434780</td>\n",
       "      <td>0.033141</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WeightedEnsemble_L2_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>182.296379</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.229273</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForestMSE_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.596197</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.596197</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNeighborsUnif_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.034130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.034130</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNeighborsDist_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.026928</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.026928</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ExtraTreesMSE_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.690349</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.690349</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CatBoost_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>178.349829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>178.349829</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model  score_val  pred_time_val     fit_time  \\\n",
       "0           WeightedEnsemble_L2 -14.043377       2.309985  1909.175653   \n",
       "1               CatBoost_BAG_L1 -14.083426       0.158970  1905.577559   \n",
       "2          ExtraTreesMSE_BAG_L1 -15.582089       0.665730     3.315713   \n",
       "3        RandomForestMSE_BAG_L1 -16.913265       0.753975    17.336973   \n",
       "4         KNeighborsDist_BAG_L1 -20.787500       1.484526     0.053108   \n",
       "5         KNeighborsUnif_BAG_L1 -20.882629       1.434780     0.033141   \n",
       "6      WeightedEnsemble_L2_FULL        NaN            NaN   182.296379   \n",
       "7   RandomForestMSE_BAG_L1_FULL        NaN            NaN    17.596197   \n",
       "8    KNeighborsUnif_BAG_L1_FULL        NaN            NaN     0.034130   \n",
       "9    KNeighborsDist_BAG_L1_FULL        NaN            NaN     0.026928   \n",
       "10    ExtraTreesMSE_BAG_L1_FULL        NaN            NaN     3.690349   \n",
       "11         CatBoost_BAG_L1_FULL        NaN            NaN   178.349829   \n",
       "\n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                 0.000759           0.229273            2       True   \n",
       "1                 0.158970        1905.577559            1       True   \n",
       "2                 0.665730           3.315713            1       True   \n",
       "3                 0.753975          17.336973            1       True   \n",
       "4                 1.484526           0.053108            1       True   \n",
       "5                 1.434780           0.033141            1       True   \n",
       "6                      NaN           0.229273            2       True   \n",
       "7                      NaN          17.596197            1       True   \n",
       "8                      NaN           0.034130            1       True   \n",
       "9                      NaN           0.026928            1       True   \n",
       "10                     NaN           3.690349            1       True   \n",
       "11                     NaN         178.349829            1       True   \n",
       "\n",
       "    fit_order  \n",
       "0           6  \n",
       "1           4  \n",
       "2           5  \n",
       "3           3  \n",
       "4           2  \n",
       "5           1  \n",
       "6          12  \n",
       "7           9  \n",
       "8           7  \n",
       "9           8  \n",
       "10         11  \n",
       "11         10  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_c.leaderboard(silent=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_a = data_collection.X_test_estimated['a'].drop(columns=['location', 'date_forecast'])\n",
    "test_b = data_collection.X_test_estimated['b'].drop(columns=['location', 'date_forecast'])\n",
    "test_c = data_collection.X_test_estimated['c'].drop(columns=['location', 'date_forecast'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_a = predictor_a.predict(test_a)\n",
    "y_pred_b = predictor_b.predict(test_b)\n",
    "y_pred_c = predictor_c.predict(test_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of final pred:  540.3197\n"
     ]
    }
   ],
   "source": [
    "final_pred = pd.concat([y_pred_a, y_pred_b, y_pred_c]).reset_index(drop=True)\n",
    "final_pred = ReLU(final_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = True\n",
    "model_name = \"AutoGluon_3\"\n",
    "\n",
    "if save:\n",
    "    pred_to_delivery(ReLU(final_pred),'Delivered_preds/' + model_name + '.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
