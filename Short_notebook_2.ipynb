{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Short 2\n",
    "\n",
    "## Ensamble model of AutoGluon and Catboost\n",
    "\n",
    "Name: Erlend Lokna, Student ID: 528564\n",
    "\n",
    "Name: Johan Vik Mathisen, Student ID: 508258\n",
    "\n",
    "\n",
    "Team name: Shaky Warriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from autogluon.tabular import TabularPredictor\n",
    "import catboost as cb\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "         \n",
    "class DataSet:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        kind: observerd, estimated, train\n",
    "        \"\"\"\n",
    "\n",
    "        train_a = pd.read_parquet('data/A/train_targets.parquet')\n",
    "        train_b = pd.read_parquet('data/B/train_targets.parquet')\n",
    "        train_c = pd.read_parquet('data/C/train_targets.parquet')\n",
    "\n",
    "        # Estimated training data for each location\n",
    "        X_train_estimated_a = pd.read_parquet('data/A/X_train_estimated.parquet')\n",
    "        X_train_estimated_b = pd.read_parquet('data/B/X_train_estimated.parquet')\n",
    "        X_train_estimated_c = pd.read_parquet('data/C/X_train_estimated.parquet')\n",
    "\n",
    "        # Observed training data for each location\n",
    "        X_train_observed_b = pd.read_parquet('data/B/X_train_observed.parquet')\n",
    "        X_train_observed_a = pd.read_parquet('data/A/X_train_observed.parquet')\n",
    "        X_train_observed_c = pd.read_parquet('data/C/X_train_observed.parquet')\n",
    "\n",
    "        # Estimated test data for each location\n",
    "        X_test_estimated_b = pd.read_parquet('data/B/X_test_estimated.parquet')\n",
    "        X_test_estimated_a = pd.read_parquet('data/A/X_test_estimated.parquet')\n",
    "        X_test_estimated_c = pd.read_parquet('data/C/X_test_estimated.parquet')\n",
    "\n",
    "        Y_train = {\n",
    "            'a': train_a, \n",
    "            'b':train_b, \n",
    "            'c':train_c\n",
    "        }\n",
    "        X_train_estimated = {\n",
    "            'a':X_train_estimated_a,\n",
    "            'b':X_train_estimated_b,\n",
    "            'c':X_train_estimated_c\n",
    "        }\n",
    "        X_train_observed = {\n",
    "            'a':X_train_observed_a,\n",
    "            'b':X_train_observed_b,\n",
    "            'c':X_train_observed_c\n",
    "        }\n",
    "        X_test_estimated = {\n",
    "            'a':X_test_estimated_a,\n",
    "            'b':X_test_estimated_b,\n",
    "            'c':X_test_estimated_c\n",
    "        }\n",
    "        self.X_train_observed =  X_train_observed\n",
    "        self.X_train_estimated = X_train_estimated\n",
    "        self.X_test_estimated = X_test_estimated\n",
    "        self.Y_train = Y_train\n",
    "\n",
    "    def resample_to_hourly(self):\n",
    "        for loc in ['a','b','c']:\n",
    "            self.X_train_observed[loc] = to_hourly(self.X_train_observed[loc])\n",
    "            self.X_train_estimated[loc] = to_hourly(self.X_train_estimated[loc])\n",
    "            self.X_test_estimated[loc] = to_hourly(self.X_test_estimated[loc])\n",
    "\n",
    "\n",
    "    def select_features(self, features):\n",
    "        \"\"\" \n",
    "        Reduces dim by selecting only features from \"features\"\n",
    "        This will remove \"date_calc\" from est.\n",
    "        \"\"\"\n",
    "        for loc in ['a','b','c']:\n",
    "            self.X_train_observed[loc] = self.X_train_observed[loc][features]\n",
    "            self.X_train_estimated[loc] = self.X_train_estimated[loc][features]\n",
    "            self.X_test_estimated[loc] = self.X_test_estimated[loc][features]\n",
    "\n",
    "    def add_type(self):\n",
    "        \"\"\"\n",
    "        0: Estimated data\n",
    "        1: Observed data\n",
    "        \"\"\"\n",
    "        for loc in ['a','b','c']:\n",
    "            type_vec_X_tr = [1] * len(self.X_train_observed[loc])\n",
    "            self.X_train_observed[loc]['type'] = type_vec_X_tr\n",
    "\n",
    "            type_vec_X_tr_e = [0] * len(self.X_train_estimated[loc])\n",
    "            self.X_train_estimated[loc]['type'] = type_vec_X_tr_e\n",
    "\n",
    "            type_vec_X_te = [0] * len(self.X_test_estimated[loc])\n",
    "            self.X_test_estimated[loc]['type'] = type_vec_X_te\n",
    "\n",
    "\n",
    "    def add_location(self):\n",
    "        \"\"\"\n",
    "        Adds a categorical feature \"location\" equal to the input string location.\n",
    "        \"\"\"\n",
    "        for loc in ['a','b','c']:\n",
    "            loc_vec_X_tr = [loc] * len(self.X_train_observed[loc])\n",
    "            self.X_train_observed[loc]['location'] = loc_vec_X_tr\n",
    "\n",
    "            loc_vec_X_tr_e = [loc] * len(self.X_train_estimated[loc])\n",
    "            self.X_train_estimated[loc]['location'] = loc_vec_X_tr_e\n",
    "\n",
    "            loc_vec_X_te = [loc] * len(self.X_test_estimated[loc])\n",
    "            self.X_test_estimated[loc]['location'] = loc_vec_X_te\n",
    "\n",
    "    def remove_nans(self, feature):\n",
    "        for loc in ['a','b','c']:\n",
    "            cols = self.X_train_observed['a'].columns\n",
    "            if feature in cols:\n",
    "                self.X_train_observed[loc] = self.X_train_observed[loc].dropna(subset = [feature], how = 'all')\n",
    "                self.X_train_estimated[loc] = self.X_train_estimated[loc].dropna(subset = [feature], how = 'all')\n",
    "                self.X_test_estimated[loc] = self.X_test_estimated[loc].dropna(subset = [feature], how = 'all')\n",
    "            else:\n",
    "                print(\"Feature not in data frame.\")\n",
    "\n",
    "    def combine_obs_est(self):\n",
    "        \"\"\"\n",
    "        Concatinates the estimated and observed data. \n",
    "        Removes data_calc from est.\n",
    "        \"\"\"\n",
    "\n",
    "        obs_a = self.X_train_observed['a']\n",
    "        est_a = self.X_train_estimated['a']\n",
    "\n",
    "        obs_b = self.X_train_observed['b']\n",
    "        est_b = self.X_train_estimated['b']\n",
    "\n",
    "        obs_c = self.X_train_observed['c']\n",
    "        est_c = self.X_train_estimated['c']\n",
    "\n",
    "        self.X_train = {\n",
    "        'a':pd.concat([obs_a, est_a]),\n",
    "        'b':pd.concat([obs_b, est_b]),\n",
    "        'c':pd.concat([obs_c, est_c])\n",
    "        }\n",
    "\n",
    "        self.X_train['a'] = self.X_train['a'].reset_index(drop=True)\n",
    "        self.X_train['b'] = self.X_train['b'].reset_index(drop=True)\n",
    "        self.X_train['c'] = self.X_train['c'].reset_index(drop=True)\n",
    "\n",
    "        self.X_train['a'], self.Y_train['a'] = match_X_Y(self.X_train['a'], self.Y_train['a'])\n",
    "        self.X_train['b'], self.Y_train['b'] = match_X_Y(self.X_train['b'], self.Y_train['b'])\n",
    "        self.X_train['c'], self.Y_train['c'] = match_X_Y(self.X_train['c'], self.Y_train['c'])\n",
    "    \n",
    "    def train_test(self):\n",
    "        \"\"\"\n",
    "        Vanilla split. \n",
    "        \"\"\"\n",
    "        X_a = self.X_train['a']\n",
    "        X_b = self.X_train['b']\n",
    "        X_c = self.X_train['c']\n",
    "\n",
    "        y_a = self.Y_train['a']\n",
    "        y_b = self.Y_train['b']\n",
    "        y_c = self.Y_train['c']\n",
    "\n",
    "        y_train = pd.concat([y_a, y_b, y_c])\n",
    "        y_train = y_train.reset_index(drop=True)\n",
    "\n",
    "        X_train = pd.concat([X_a, X_b, X_c])\n",
    "        X_test = pd.concat([self.X_test_estimated['a'], self.X_test_estimated['b'],self.X_test_estimated['c']])\n",
    "        \n",
    "        return X_train, X_test, y_train\n",
    "\n",
    "    def scale_y_train(self, k_b = 5, k_c = 6):\n",
    "\n",
    "        self.Y_train['b'] = self.Y_train['b'] * k_b \n",
    "        self.Y_train['c'] = self.Y_train['c']* k_c\n",
    "\n",
    "    def drop_bad_data(self):\n",
    "        for loc in ['a', 'b', 'c']:\n",
    "            y_ind = get_constant_indices(self.Y_train[loc])\n",
    "            self.Y_train[loc].drop(y_ind, errors='ignore')\n",
    "            self.X_train[loc].drop(y_ind, errors='ignore')\n",
    "\n",
    "\n",
    "    def cyclic_time_encoding(self):\n",
    "        for loc in ['a', 'b', 'c']:\n",
    "            for time_feature in [\"time\", \"date_forecast\"]:\n",
    "                if time_feature in self.X_train[loc].columns:\n",
    "                    self.X_train[loc]['sin_hour'] = np.sin(2*np.pi*self.X_train[loc][time_feature].dt.hour/24)\n",
    "                    self.X_train[loc]['sin_month'] = np.sin(2*np.pi*self.X_train[loc][time_feature].dt.month/12)\n",
    "\n",
    "                    self.X_train[loc]['cos_hour'] = np.cos(2*np.pi*self.X_train[loc][time_feature].dt.hour/24)\n",
    "                    self.X_train[loc]['cos_month'] = np.cos(2*np.pi*self.X_train[loc][time_feature].dt.month/12)\n",
    "                if time_feature in self.X_test_estimated[loc].columns:    \n",
    "                    self.X_test_estimated[loc]['sin_hour'] = np.sin(2*np.pi*self.X_test_estimated[loc][time_feature].dt.hour/24)\n",
    "                    self.X_test_estimated[loc]['sin_month'] = np.sin(2*np.pi*self.X_test_estimated[loc][time_feature].dt.month/12)\n",
    "\n",
    "                    self.X_test_estimated[loc]['cos_hour'] = np.cos(2*np.pi*self.X_test_estimated[loc][time_feature].dt.hour/24)\n",
    "                    self.X_test_estimated[loc]['cos_month'] = np.cos(2*np.pi*self.X_test_estimated[loc][time_feature].dt.month/12)\n",
    "\n",
    "#Helper functions\n",
    "\n",
    "def match_X_Y(X,Y):\n",
    "    \"\"\" \n",
    "    date_forecast and time must be unique!\n",
    "    Matches the timestamps of X to the timestamps of Y. \n",
    "    Makes sure that the length of X and Y are equal.\n",
    "    \"\"\"\n",
    "    Y = Y.dropna()\n",
    "    X = X.rename(columns={'date_forecast': 'time'})\n",
    "    merge_df = Y.merge(X, on=\"time\", how='inner')\n",
    "    Y = merge_df['pv_measurement']\n",
    "    X = merge_df.drop(columns = ['pv_measurement'])\n",
    "    return X,Y\n",
    "\n",
    "def to_hourly(df):\n",
    "    df['date_forecast']\n",
    "    df.set_index('date_forecast', inplace=True)\n",
    "    df = df.resample('H').mean()\n",
    "    df.reset_index(inplace=True)\n",
    "    return df\n",
    "\n",
    "def make_categorical(data, feature_list):\n",
    "    for feature in feature_list:\n",
    "        data[feature] = data[feature].astype('category')\n",
    "\n",
    "\n",
    "def ReLU(x):\n",
    "    return x * (x > 0)\n",
    "\n",
    "def remap(x):\n",
    "    if x<0.5:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "\n",
    "def get_constant_indices(ser):\n",
    "    mask = (ser != 0)\n",
    "    constant_periods = ser[mask].groupby((ser[mask] != ser[mask].shift()).cumsum()).cumcount().add(1)\n",
    "    \n",
    "    drop_mask = constant_periods >= 12\n",
    "    return constant_periods[drop_mask].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['date_forecast', 'absolute_humidity_2m:gm3',\n",
    "       'clear_sky_energy_1h:J', 'clear_sky_rad:W',\n",
    "       'cloud_base_agl:m', 'dew_or_rime:idx', 'dew_point_2m:K',\n",
    "       'diffuse_rad:W', 'diffuse_rad_1h:J', 'direct_rad:W', 'direct_rad_1h:J',\n",
    "       'effective_cloud_cover:p', 'elevation:m', 'fresh_snow_12h:cm',\n",
    "       'fresh_snow_1h:cm', 'fresh_snow_24h:cm', 'fresh_snow_3h:cm',\n",
    "       'fresh_snow_6h:cm', 'is_in_shadow:idx', 'is_day:idx', \n",
    "       'msl_pressure:hPa', 'precip_5min:mm', 'precip_type_5min:idx',\n",
    "       'pressure_100m:hPa', 'pressure_50m:hPa', 'prob_rime:p',\n",
    "       'rain_water:kgm2', 'relative_humidity_1000hPa:p', 'sfc_pressure:hPa',\n",
    "       'snow_depth:cm', 'snow_drift:idx',\n",
    "       'snow_melt_10min:mm', 'snow_water:kgm2', 'sun_azimuth:d',\n",
    "       'sun_elevation:d', 'super_cooled_liquid_water:kgm2', 't_1000hPa:K',\n",
    "       'total_cloud_cover:p', 'visibility:m', 'wind_speed_10m:ms',\n",
    "       'wind_speed_u_10m:ms', 'wind_speed_v_10m:ms', 'wind_speed_w_1000hPa:ms']\n",
    "\n",
    "made_features = ['location', 'type', 'is_day:idx', 'is_in_shadow:idx', 'dew_or_rime:idx']\n",
    "\n",
    "drop_feature = 'diffuse_rad:W'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collection = DataSet()\n",
    "data_collection.select_features(selected_features)\n",
    "data_collection.resample_to_hourly()\n",
    "data_collection.remove_nans(drop_feature)\n",
    "data_collection.add_location()\n",
    "data_collection.add_type()\n",
    "\n",
    "data_collection.combine_obs_est()\n",
    "data_collection.drop_bad_data()\n",
    "data_collection.cyclic_time_encoding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_a = data_collection.X_train['a']\n",
    "X_b = data_collection.X_train['b']\n",
    "X_c = data_collection.X_train['c']\n",
    "\n",
    "y_a = data_collection.Y_train['a']\n",
    "y_b = data_collection.Y_train['b']\n",
    "y_c = data_collection.Y_train['c']\n",
    "\n",
    "for f in made_features:\n",
    "    if f not in ['location', 'type']:\n",
    "        X_a[f] = X_a[f].map(remap)\n",
    "        X_b[f] = X_b[f].map(remap)\n",
    "        X_c[f] = X_c[f].map(remap)\n",
    "\n",
    "make_categorical(X_a,made_features)\n",
    "make_categorical(X_b,made_features)\n",
    "make_categorical(X_c,made_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "drop_cols = ['location', 'time']\n",
    "\n",
    "df_a = pd.concat([X_a, y_a], axis=1).drop(columns=drop_cols)\n",
    "df_b = pd.concat([X_b, y_b], axis=1).drop(columns=drop_cols)\n",
    "df_c = pd.concat([X_c, y_c], axis=1).drop(columns=drop_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 246\n",
    "\n",
    "data = dict()\n",
    "\n",
    "# sample 50% of the data for each building with type = 0\n",
    "df_a_tune = df_a[df_a['type'] == 0].sample(frac=0.5, random_state=seed)\n",
    "df_b_tune = df_b[df_b['type'] == 0].sample(frac=0.5, random_state=seed)   \n",
    "df_c_tune = df_c[df_c['type'] == 0].sample(frac=0.5, random_state=seed)\n",
    "\n",
    "# drop these rows from the original data\n",
    "df_a_train = df_a.drop(df_a_tune.index)\n",
    "df_b_train = df_b.drop(df_b_tune.index)\n",
    "df_c_train = df_c.drop(df_c_tune.index)\n",
    "\n",
    "data['a'] = [df_a_train, df_a_tune]\n",
    "data['b'] = [df_b_train, df_b_tune]\n",
    "data['c'] = [df_c_train, df_c_tune]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 hours (per model)\n",
    "time_in_sek = 60*60*2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231109_184819/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 6s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231109_184819/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.10.7\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 19.6.0: Thu Jan 13 01:26:33 PST 2022; root:xnu-6153.141.51~3/RELEASE_X86_64\n",
      "Disk Space Avail:   245.31 GB / 500.07 GB (49.1%)\n",
      "Train Data Rows:    31864\n",
      "Train Data Columns: 47\n",
      "Tuning Data Rows:    2197\n",
      "Tuning Data Columns: 47\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (5733.42, 0.0, 650.65332, 1179.83452)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1749.62 MB\n",
      "\tTrain Data (Original)  Memory Usage: 6.54 MB (0.4% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 2): ['elevation:m', 'snow_drift:idx']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  4 | ['dew_or_rime:idx', 'is_in_shadow:idx', 'is_day:idx', 'type']\n",
      "\t\t('float', [])    : 41 | ['absolute_humidity_2m:gm3', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', 'cloud_base_agl:m', 'dew_point_2m:K', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 41 | ['absolute_humidity_2m:gm3', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', 'cloud_base_agl:m', 'dew_point_2m:K', ...]\n",
      "\t\t('int', ['bool']) :  4 | ['dew_or_rime:idx', 'is_in_shadow:idx', 'is_day:idx', 'type']\n",
      "\t0.3s = Fit runtime\n",
      "\t45 features in original data used to generate 45 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 6.27 MB (0.4% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.43s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "use_bag_holdout=True, will use tuning_data as holdout (will not be used for early stopping).\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 5.57s of the 5.57s of remaining time.\n",
      "\t-170.5398\t = Validation score   (-mean_absolute_error)\n",
      "\t0.08s\t = Training   runtime\n",
      "\t2.77s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 2.36s of the 2.36s of remaining time.\n",
      "\t-170.2365\t = Validation score   (-mean_absolute_error)\n",
      "\t0.08s\t = Training   runtime\n",
      "\t2.65s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 5.57s of the -0.85s of remaining time.\n",
      "\t-170.2123\t = Validation score   (-mean_absolute_error)\n",
      "\t0.22s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 7.13s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231109_184819/\")\n"
     ]
    }
   ],
   "source": [
    "label = 'pv_measurement'\n",
    "predictor_a = TabularPredictor(label=label, eval_metric='mae').fit(\n",
    "    train_data = data['a'][0], \n",
    "    time_limit = time_in_sek,\n",
    "    presets='best_quality',\n",
    "    num_bag_folds=8,\n",
    "    num_stack_levels=0,\n",
    "    tuning_data = data['a'][1],\n",
    "    use_bag_holdout= True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231109_184826/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 6s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231109_184826/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.10.7\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 19.6.0: Thu Jan 13 01:26:33 PST 2022; root:xnu-6153.141.51~3/RELEASE_X86_64\n",
      "Disk Space Avail:   245.29 GB / 500.07 GB (49.1%)\n",
      "Train Data Rows:    31019\n",
      "Train Data Columns: 47\n",
      "Tuning Data Rows:    1800\n",
      "Tuning Data Columns: 47\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (1152.3, -0.0, 99.69624, 196.54802)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1681.29 MB\n",
      "\tTrain Data (Original)  Memory Usage: 6.3 MB (0.4% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['elevation:m']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  4 | ['dew_or_rime:idx', 'is_in_shadow:idx', 'is_day:idx', 'type']\n",
      "\t\t('float', [])    : 42 | ['absolute_humidity_2m:gm3', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', 'cloud_base_agl:m', 'dew_point_2m:K', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 42 | ['absolute_humidity_2m:gm3', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', 'cloud_base_agl:m', 'dew_point_2m:K', ...]\n",
      "\t\t('int', ['bool']) :  4 | ['dew_or_rime:idx', 'is_in_shadow:idx', 'is_day:idx', 'type']\n",
      "\t0.4s = Fit runtime\n",
      "\t46 features in original data used to generate 46 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 6.17 MB (0.4% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.5s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "use_bag_holdout=True, will use tuning_data as holdout (will not be used for early stopping).\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 5.5s of the 5.5s of remaining time.\n",
      "\t-30.5762\t = Validation score   (-mean_absolute_error)\n",
      "\t0.08s\t = Training   runtime\n",
      "\t3.22s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 1.81s of the 1.81s of remaining time.\n",
      "\t-30.6245\t = Validation score   (-mean_absolute_error)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t2.85s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 5.5s of the -1.5s of remaining time.\n",
      "\t-30.5529\t = Validation score   (-mean_absolute_error)\n",
      "\t0.18s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 7.73s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231109_184826/\")\n"
     ]
    }
   ],
   "source": [
    "predictor_b = TabularPredictor(label=label, eval_metric='mae').fit(\n",
    "    train_data = data['b'][0], \n",
    "    time_limit = time_in_sek,\n",
    "    presets='best_quality',\n",
    "    num_bag_folds=8,\n",
    "    num_stack_levels=0,\n",
    "    tuning_data = data['b'][1],\n",
    "    use_bag_holdout=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231109_184834/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 6s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231109_184834/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.10.7\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 19.6.0: Thu Jan 13 01:26:33 PST 2022; root:xnu-6153.141.51~3/RELEASE_X86_64\n",
      "Disk Space Avail:   245.27 GB / 500.07 GB (49.0%)\n",
      "Train Data Rows:    24606\n",
      "Train Data Columns: 47\n",
      "Tuning Data Rows:    1465\n",
      "Tuning Data Columns: 47\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and label-values can't be converted to int).\n",
      "\tLabel info (max, min, mean, stddev): (999.6, 0.0, 79.70535, 168.37633)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1675.24 MB\n",
      "\tTrain Data (Original)  Memory Usage: 5.01 MB (0.3% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 2): ['elevation:m', 'snow_drift:idx']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  4 | ['dew_or_rime:idx', 'is_in_shadow:idx', 'is_day:idx', 'type']\n",
      "\t\t('float', [])    : 41 | ['absolute_humidity_2m:gm3', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', 'cloud_base_agl:m', 'dew_point_2m:K', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 41 | ['absolute_humidity_2m:gm3', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', 'cloud_base_agl:m', 'dew_point_2m:K', ...]\n",
      "\t\t('int', ['bool']) :  4 | ['dew_or_rime:idx', 'is_in_shadow:idx', 'is_day:idx', 'type']\n",
      "\t0.2s = Fit runtime\n",
      "\t45 features in original data used to generate 45 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 4.8 MB (0.3% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.26s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "use_bag_holdout=True, will use tuning_data as holdout (will not be used for early stopping).\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 5.74s of the 5.74s of remaining time.\n",
      "\t-20.8779\t = Validation score   (-mean_absolute_error)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t1.83s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 3.49s of the 3.49s of remaining time.\n",
      "\t-20.7787\t = Validation score   (-mean_absolute_error)\n",
      "\t0.06s\t = Training   runtime\n",
      "\t1.74s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1.44s of the 1.43s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t_format_eval_result() missing 1 required positional argument: 'show_stdv'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 169, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 266, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 592, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 309, in after_all_folds_scheduled\n",
      "    self._fit_fold_model(job)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 314, in _fit_fold_model\n",
      "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 349, in _fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 194, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 124, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/lightgbm/engine.py\", line 286, in train\n",
      "    cb(callback.CallbackEnv(model=booster,\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/tabular/models/lgb/callbacks.py\", line 240, in _callback\n",
      "    + \". Best iteration is:\\n\\t[%d]\\t%s\" % (best_iter[i] + 1, \"\\t\".join([_format_eval_result(x) for x in best_score_list[i]])),\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/tabular/models/lgb/callbacks.py\", line 240, in <listcomp>\n",
      "    + \". Best iteration is:\\n\\t[%d]\\t%s\" % (best_iter[i] + 1, \"\\t\".join([_format_eval_result(x) for x in best_score_list[i]])),\n",
      "TypeError: _format_eval_result() missing 1 required positional argument: 'show_stdv'\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1.07s of the 1.07s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBM_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t_format_eval_result() missing 1 required positional argument: 'show_stdv'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1733, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1684, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 169, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 266, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 592, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 309, in after_all_folds_scheduled\n",
      "    self._fit_fold_model(job)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 314, in _fit_fold_model\n",
      "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 349, in _fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 194, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 124, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/lightgbm/engine.py\", line 286, in train\n",
      "    cb(callback.CallbackEnv(model=booster,\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/tabular/models/lgb/callbacks.py\", line 240, in _callback\n",
      "    + \". Best iteration is:\\n\\t[%d]\\t%s\" % (best_iter[i] + 1, \"\\t\".join([_format_eval_result(x) for x in best_score_list[i]])),\n",
      "  File \"/Users/johanvikmathisen/Desktop/Fag/Matematikk/Solar-Energy-Prediction/myenv/lib/python3.10/site-packages/autogluon/tabular/models/lgb/callbacks.py\", line 240, in <listcomp>\n",
      "    + \". Best iteration is:\\n\\t[%d]\\t%s\" % (best_iter[i] + 1, \"\\t\".join([_format_eval_result(x) for x in best_score_list[i]])),\n",
      "TypeError: _format_eval_result() missing 1 required positional argument: 'show_stdv'\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 0.74s of the 0.74s of remaining time.\n",
      "\tWarning: Model is expected to require 38.8s to train, which exceeds the maximum time limit of 0.7s, skipping model...\n",
      "\tTime limit exceeded... Skipping RandomForestMSE_BAG_L1.\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 0.14s of the 0.14s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTime limit exceeded... Skipping CatBoost_BAG_L1.\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 0.04s of the 0.04s of remaining time.\n",
      "\tWarning: Model is expected to require 9.4s to train, which exceeds the maximum time limit of 0.0s, skipping model...\n",
      "\tTime limit exceeded... Skipping ExtraTreesMSE_BAG_L1.\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 5.74s of the -0.17s of remaining time.\n",
      "\t-20.7787\t = Validation score   (-mean_absolute_error)\n",
      "\t0.11s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 6.32s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231109_184834/\")\n"
     ]
    }
   ],
   "source": [
    "predictor_c = TabularPredictor(label=label, eval_metric='mae').fit(\n",
    "    train_data = data['c'][0], \n",
    "    time_limit = time_in_sek,\n",
    "    presets='best_quality',\n",
    "    num_bag_folds=8,\n",
    "    num_stack_levels=0,\n",
    "    tuning_data = data['c'][1],\n",
    "    use_bag_holdout=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1_FULL ...\n",
      "\t0.06s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: KNeighborsDist_BAG_L1_FULL ...\n",
      "\t0.05s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.22s\t = Training   runtime\n",
      "Updated best model to \"WeightedEnsemble_L2_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"WeightedEnsemble_L2_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 0.31s\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1_FULL ...\n",
      "\t0.04s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: KNeighborsDist_BAG_L1_FULL ...\n",
      "\t0.05s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.18s\t = Training   runtime\n",
      "Updated best model to \"WeightedEnsemble_L2_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"WeightedEnsemble_L2_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 0.26s\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1_FULL ...\n",
      "\t0.04s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: KNeighborsDist_BAG_L1_FULL ...\n",
      "\t0.04s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.11s\t = Training   runtime\n",
      "Updated best model to \"WeightedEnsemble_L2_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"WeightedEnsemble_L2_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 0.25s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'KNeighborsUnif_BAG_L1': 'KNeighborsUnif_BAG_L1_FULL',\n",
       " 'KNeighborsDist_BAG_L1': 'KNeighborsDist_BAG_L1_FULL',\n",
       " 'WeightedEnsemble_L2': 'WeightedEnsemble_L2_FULL'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_a.refit_full()\n",
    "predictor_b.refit_full()\n",
    "predictor_c.refit_full()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-170.212313</td>\n",
       "      <td>5.421933</td>\n",
       "      <td>0.382748</td>\n",
       "      <td>0.000973</td>\n",
       "      <td>0.223835</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNeighborsDist_BAG_L1</td>\n",
       "      <td>-170.236486</td>\n",
       "      <td>2.651033</td>\n",
       "      <td>0.075200</td>\n",
       "      <td>2.651033</td>\n",
       "      <td>0.075200</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighborsUnif_BAG_L1</td>\n",
       "      <td>-170.539814</td>\n",
       "      <td>2.769927</td>\n",
       "      <td>0.083713</td>\n",
       "      <td>2.769927</td>\n",
       "      <td>0.083713</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WeightedEnsemble_L2_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.333289</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.223835</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNeighborsUnif_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.059974</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.059974</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNeighborsDist_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.049480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.049480</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model   score_val  pred_time_val  fit_time  \\\n",
       "0         WeightedEnsemble_L2 -170.212313       5.421933  0.382748   \n",
       "1       KNeighborsDist_BAG_L1 -170.236486       2.651033  0.075200   \n",
       "2       KNeighborsUnif_BAG_L1 -170.539814       2.769927  0.083713   \n",
       "3    WeightedEnsemble_L2_FULL         NaN            NaN  0.333289   \n",
       "4  KNeighborsUnif_BAG_L1_FULL         NaN            NaN  0.059974   \n",
       "5  KNeighborsDist_BAG_L1_FULL         NaN            NaN  0.049480   \n",
       "\n",
       "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                0.000973           0.223835            2       True   \n",
       "1                2.651033           0.075200            1       True   \n",
       "2                2.769927           0.083713            1       True   \n",
       "3                     NaN           0.223835            2       True   \n",
       "4                     NaN           0.059974            1       True   \n",
       "5                     NaN           0.049480            1       True   \n",
       "\n",
       "   fit_order  \n",
       "0          3  \n",
       "1          2  \n",
       "2          1  \n",
       "3          6  \n",
       "4          4  \n",
       "5          5  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_a.leaderboard(silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-30.552871</td>\n",
       "      <td>6.074384</td>\n",
       "      <td>0.349036</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>0.181784</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNeighborsUnif_BAG_L1</td>\n",
       "      <td>-30.576173</td>\n",
       "      <td>3.218800</td>\n",
       "      <td>0.076689</td>\n",
       "      <td>3.218800</td>\n",
       "      <td>0.076689</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighborsDist_BAG_L1</td>\n",
       "      <td>-30.624493</td>\n",
       "      <td>2.854934</td>\n",
       "      <td>0.090563</td>\n",
       "      <td>2.854934</td>\n",
       "      <td>0.090563</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WeightedEnsemble_L2_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.269425</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.181784</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNeighborsUnif_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.042561</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.042561</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNeighborsDist_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.045080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.045080</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model  score_val  pred_time_val  fit_time  \\\n",
       "0         WeightedEnsemble_L2 -30.552871       6.074384  0.349036   \n",
       "1       KNeighborsUnif_BAG_L1 -30.576173       3.218800  0.076689   \n",
       "2       KNeighborsDist_BAG_L1 -30.624493       2.854934  0.090563   \n",
       "3    WeightedEnsemble_L2_FULL        NaN            NaN  0.269425   \n",
       "4  KNeighborsUnif_BAG_L1_FULL        NaN            NaN  0.042561   \n",
       "5  KNeighborsDist_BAG_L1_FULL        NaN            NaN  0.045080   \n",
       "\n",
       "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                0.000650           0.181784            2       True   \n",
       "1                3.218800           0.076689            1       True   \n",
       "2                2.854934           0.090563            1       True   \n",
       "3                     NaN           0.181784            2       True   \n",
       "4                     NaN           0.042561            1       True   \n",
       "5                     NaN           0.045080            1       True   \n",
       "\n",
       "   fit_order  \n",
       "0          3  \n",
       "1          1  \n",
       "2          2  \n",
       "3          6  \n",
       "4          4  \n",
       "5          5  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_b.leaderboard(silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsDist_BAG_L1</td>\n",
       "      <td>-20.778725</td>\n",
       "      <td>1.742053</td>\n",
       "      <td>0.064517</td>\n",
       "      <td>1.742053</td>\n",
       "      <td>0.064517</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-20.778725</td>\n",
       "      <td>1.742646</td>\n",
       "      <td>0.178675</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>0.114158</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighborsUnif_BAG_L1</td>\n",
       "      <td>-20.877947</td>\n",
       "      <td>1.831164</td>\n",
       "      <td>0.162366</td>\n",
       "      <td>1.831164</td>\n",
       "      <td>0.162366</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WeightedEnsemble_L2_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.154097</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.114158</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNeighborsUnif_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.043888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.043888</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNeighborsDist_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.039939</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.039939</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model  score_val  pred_time_val  fit_time  \\\n",
       "0       KNeighborsDist_BAG_L1 -20.778725       1.742053  0.064517   \n",
       "1         WeightedEnsemble_L2 -20.778725       1.742646  0.178675   \n",
       "2       KNeighborsUnif_BAG_L1 -20.877947       1.831164  0.162366   \n",
       "3    WeightedEnsemble_L2_FULL        NaN            NaN  0.154097   \n",
       "4  KNeighborsUnif_BAG_L1_FULL        NaN            NaN  0.043888   \n",
       "5  KNeighborsDist_BAG_L1_FULL        NaN            NaN  0.039939   \n",
       "\n",
       "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                1.742053           0.064517            1       True   \n",
       "1                0.000593           0.114158            2       True   \n",
       "2                1.831164           0.162366            1       True   \n",
       "3                     NaN           0.114158            2       True   \n",
       "4                     NaN           0.043888            1       True   \n",
       "5                     NaN           0.039939            1       True   \n",
       "\n",
       "   fit_order  \n",
       "0          2  \n",
       "1          3  \n",
       "2          1  \n",
       "3          6  \n",
       "4          4  \n",
       "5          5  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_c.leaderboard(silent=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_a = data_collection.X_test_estimated['a'].drop(columns=['location', 'date_forecast'])\n",
    "test_b = data_collection.X_test_estimated['b'].drop(columns=['location', 'date_forecast'])\n",
    "test_c = data_collection.X_test_estimated['c'].drop(columns=['location', 'date_forecast'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_a = predictor_a.predict(test_a)\n",
    "y_pred_b = predictor_b.predict(test_b)\n",
    "y_pred_c = predictor_c.predict(test_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = pd.concat([y_pred_a, y_pred_b, y_pred_c]).reset_index(drop=True)\n",
    "final_pred_AutoGluon = ReLU(final_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['date_forecast', 'absolute_humidity_2m:gm3',\n",
    "       'air_density_2m:kgm3', 'clear_sky_energy_1h:J',\n",
    "       'clear_sky_rad:W', 'dew_or_rime:idx',\n",
    "       'dew_point_2m:K', 'diffuse_rad:W', 'diffuse_rad_1h:J', 'direct_rad:W',\n",
    "       'direct_rad_1h:J', 'effective_cloud_cover:p', 'elevation:m',\n",
    "       'fresh_snow_6h:cm', 'is_day:idx',\n",
    "       'is_in_shadow:idx', 'msl_pressure:hPa', 'precip_5min:mm',\n",
    "       'pressure_100m:hPa', 'pressure_50m:hPa',\n",
    "       'prob_rime:p', 'rain_water:kgm2', 'relative_humidity_1000hPa:p',\n",
    "       'sfc_pressure:hPa', 'snow_depth:cm',\n",
    "       'sun_azimuth:d', 'sun_elevation:d', 'super_cooled_liquid_water:kgm2',\n",
    "       't_1000hPa:K', 'total_cloud_cover:p', 'visibility:m',\n",
    "       'wind_speed_10m:ms', 'wind_speed_u_10m:ms', 'wind_speed_v_10m:ms',\n",
    "       'wind_speed_w_1000hPa:ms']\n",
    "\n",
    "made_features = ['location', 'type', 'is_day:idx', 'is_in_shadow:idx', 'dew_or_rime:idx']\n",
    "\n",
    "drop_feature = 'diffuse_rad:W'\n",
    "\n",
    "\n",
    "#Loading all data\n",
    "data_collection = DataSet()\n",
    "#Preprocessing\n",
    "data_collection.select_features(selected_features)\n",
    "data_collection.resample_to_hourly()\n",
    "data_collection.remove_nans(drop_feature)\n",
    "data_collection.add_location()\n",
    "data_collection.add_type()\n",
    "data_collection.combine_obs_est()\n",
    "data_collection.drop_bad_data()\n",
    "data_collection.cyclic_time_encoding()\n",
    "\n",
    "k_b = 5\n",
    "k_c = 6\n",
    "data_collection.scale_y_train(k_b = k_b, k_c = k_c)\n",
    "\n",
    "X_train, X_test, y_train = data_collection.train_test()\n",
    "\n",
    "for f in made_features:\n",
    "    if f not in ['location', 'type']:\n",
    "        X_train[f] = X_train[f].map(remap)\n",
    "        X_test[f] = X_test[f].map(remap)\n",
    "\n",
    "make_categorical(X_train,made_features)\n",
    "X_train = X_train.drop('time', axis=1)\n",
    "\n",
    "make_categorical(X_test,made_features)\n",
    "X_test = X_test.drop('date_forecast', axis=1)\n",
    "\n",
    "train_pool = cb.Pool(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cat_features = made_features\n",
    ")\n",
    "test_pool = cb.Pool(\n",
    "    X_test,\n",
    "    cat_features = made_features\n",
    ")\n",
    "\n",
    "model = cb.CatBoostRegressor(\n",
    "    iterations = 10000,\n",
    "    depth = 9,\n",
    "    learning_rate =0.005,\n",
    "    loss_function ='MAE',\n",
    "    cat_features = made_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model\n",
    "model.fit(train_pool, silent=True)\n",
    "# make the prediction using the resulting model\n",
    "preds = model.predict(test_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale back\n",
    "length = int((X_test.shape[0]/3))\n",
    "pred_a = preds[:length]\n",
    "pred_b = preds[length:2*length] / k_b\n",
    "pred_c = preds[2*length:3*length] / k_c\n",
    "preds = np.concatenate([pred_a,pred_b, pred_c])\n",
    "#Drop negative values\n",
    "final_pred_cb = ReLU(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining for final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred_AutoGluon = pd.DataFrame({'predictions':final_pred_AutoGluon})\n",
    "final_pred_AutoGluon['predictions'] = final_pred_AutoGluon['predictions'].apply(lambda x: 0 if x < 5 else x)\n",
    "\n",
    "final_pred_AutoGluon.reset_index()\n",
    "final_pred_AutoGluon = final_pred_AutoGluon.rename(columns={'index': 'id'})\n",
    "\n",
    "final_pred_cb = pd.DataFrame({'predictions':final_pred_cb})\n",
    "final_pred_cb['predictions'] = final_pred_cb['predictions'].apply(lambda x: 0 if x < 5 else x)\n",
    "\n",
    "final_pred_cb.reset_index()\n",
    "final_pred_cb = final_pred_cb.rename(columns={'index': 'id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.018281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.109775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2155</th>\n",
       "      <td>34.383669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2156</th>\n",
       "      <td>3.974511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157</th>\n",
       "      <td>4.771526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2158</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2159</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2160 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      predictions\n",
       "0        0.000000\n",
       "1        0.000000\n",
       "2        0.000000\n",
       "3       24.018281\n",
       "4      100.109775\n",
       "...           ...\n",
       "2155    34.383669\n",
       "2156     3.974511\n",
       "2157     4.771526\n",
       "2158     0.000000\n",
       "2159     0.000000\n",
       "\n",
       "[2160 rows x 1 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pred = 0.5*(final_pred_AutoGluon + final_pred_cb)\n",
    "\n",
    "final_pred.to_csv('Delivered_preds/final_cb_autoG.csv', index=True)\n",
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
